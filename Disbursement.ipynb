{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99ecde20-fafc-467d-ae07-47bb805e40e8",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3905abf5-417d-40f2-ab88-f8e1b3c9a23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, gc\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "data_root = 'datawarehouse/' # '../../../data/ivy-hip-fasa/datawarehouse/'\n",
    "filenames = os.listdir(data_root)\n",
    "print(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5955c973-c529-48c0-8a1f-42cf120c92f6",
   "metadata": {},
   "source": [
    "# Load Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8d938f",
   "metadata": {},
   "source": [
    "## ACADEMIC_PROGRAM_FACT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314c0e46-1862-4c3b-a78c-9906aadd5b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "academic_program_fact = pd.read_csv(data_root + 'ACADEMIC_PROGRAM_FACT.csv')\n",
    "column_mask = [col for col in academic_program_fact.columns if 'ETL' not in col]\n",
    "academic_program_fact= academic_program_fact[column_mask]\n",
    "academic_program_fact.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af0dd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "academic_program_fact['ACADEMIC_PROGRAM_STATUS'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "930f8fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we only need active students\n",
    "# commented out for now, since students who are not active now, might get aid when they were active\n",
    "academic_program_fact = academic_program_fact[\n",
    "    academic_program_fact['ACADEMIC_PROGRAM_STATUS']=='Active in Program'\n",
    "]\n",
    "\n",
    "# next we don't need this single valued column anymore\n",
    "academic_program_fact.drop(\n",
    "    columns=[\n",
    "        'ACADEMIC_PROGRAM_STATUS', 'ACADEMIC_PROGRAM_FACT_ID', \n",
    "        'ADMIT_TYPE_DIM_ID', 'ADMIT_TERM_DIM_ID'\n",
    "    ], inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15334087",
   "metadata": {},
   "outputs": [],
   "source": [
    "academic_program_fact.drop_duplicates(\n",
    "    subset=['ACADEMIC_PROGRAM_DIM_ID', 'PARTY_DIM_ID'],\n",
    "    inplace=True\n",
    ")\n",
    "print(academic_program_fact.shape)\n",
    "academic_program_fact.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd040a5",
   "metadata": {},
   "source": [
    "## ACADEMIC_PLAN_DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09832f40-4157-4815-9323-14cbeeb888c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "academic_plan_dim = pd.read_csv(data_root + 'ACADEMIC_PLAN_DIM.csv')\n",
    "column_mask = [col for col in academic_plan_dim.columns if 'ETL' not in col]\n",
    "academic_plan_dim= academic_plan_dim[column_mask]\n",
    "academic_plan_dim.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68fde870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are only evaluating undergrads\n",
    "academic_plan_dim = academic_plan_dim[academic_plan_dim['ACADEMIC_CAREER']=='UGRD']\n",
    "\n",
    "# not necessary if undergrad is the only value\n",
    "academic_plan_dim.drop(\n",
    "    columns=['ACADEMIC_CAREER', 'ACADEMIC_CAREER_DESC'], \n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae5a510",
   "metadata": {},
   "source": [
    "## ACADEMIC_PROGRAM_DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b6c6fa-9c93-4e41-98b1-1b623ea518a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "academic_program_dim = pd.read_csv(data_root + 'ACADEMIC_PROGRAM_DIM.csv')\n",
    "column_mask = [col for col in academic_program_dim.columns if 'ETL' not in col]\n",
    "academic_program_dim = academic_program_dim[column_mask]\n",
    "\n",
    "academic_program_dim.dropna(inplace=True)\n",
    "academic_program_dim['ACADEMIC_PROGRAM_DESC'] = academic_program_dim[\n",
    "    'ACADEMIC_PROGRAM_DESC'].apply(lambda x: x.replace(' Undergraduate', ''))\n",
    "academic_program_dim.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce1df24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "academic_program_dim.drop(\n",
    "    columns='ACADEMIC_CAREER_DESC', inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cb90ac",
   "metadata": {},
   "source": [
    "## DISBURSEMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c0972b-5f49-42e9-84ab-66f36248e395",
   "metadata": {},
   "outputs": [],
   "source": [
    "disbursement = pd.read_csv(data_root + 'DISBURSEMENT_UGRD_20142015.csv')\n",
    "disbursement.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0b2632",
   "metadata": {},
   "outputs": [],
   "source": [
    "disbursement.groupby('AID_YEAR')['OFFER_BALANCE'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6b6c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# incomplete info for academic year 2023 or air year 2024\n",
    "disbursement = disbursement[disbursement['AID_YEAR']<=2024].reset_index(drop=True)\n",
    "\n",
    "# to identify each disbursement uniquely. \n",
    "disbursement = disbursement.reset_index(names='DISBURSEMENT_ID')\n",
    "disbursement.drop(\n",
    "    columns=[\n",
    "        'ACADEMIC_CAREER', 'ITEM_TYPE', \n",
    "        'AID_YEAR_DESC', 'ITEM_TYPE_DESC', \n",
    "        'DISBURSEMENT_DESC'], \n",
    "    inplace=True\n",
    ")\n",
    "disbursement.groupby('AID_YEAR')['OFFER_BALANCE'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5902cec",
   "metadata": {},
   "source": [
    "### Access UVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0a92db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "access_uva = pd.read_csv('Access UVA.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24eeddfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['UVA_ACCESS', 'SCHEV', 'Need based']\n",
    "access_uva = access_uva[columns]\n",
    "result = {\n",
    "    col:[] for col in columns\n",
    "}\n",
    "\n",
    "for row in access_uva.values:\n",
    "    category, schev, need_based = row\n",
    "    \n",
    "    scheves = [i.strip() for i in schev.split(',')]\n",
    "    N = len(scheves)\n",
    "    \n",
    "    result[columns[0]].extend([category]*N)\n",
    "    result[columns[1]].extend(scheves)\n",
    "    result[columns[2]].extend([need_based]*N)\n",
    "    \n",
    "result = pd.DataFrame(result)\n",
    "result.rename({'SCHEV': 'REPORT_CODE'}, axis=1, inplace=1)\n",
    "result.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3af611a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(disbursement['REPORT_CODE'].unique()) & set(result['REPORT_CODE'].unique()))\n",
    "print(set(disbursement['REPORT_CODE'].unique()) - set(result['REPORT_CODE'].unique()))\n",
    "print(set(result['REPORT_CODE'].unique()) - set(disbursement['REPORT_CODE'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "199ee824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inner join drops non-access uva reports . e.g. XXX\n",
    "disbursement = disbursement.merge(result, on='REPORT_CODE', how='inner')\n",
    "\n",
    "# disbursement['Legacy Category order of money'].fillna('Non Access UVA', inplace=True)\n",
    "# disbursement['Need based'].fillna('NA', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3f6438",
   "metadata": {},
   "source": [
    "## IAS_STUDENT_INFO_V_UGRD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdcf5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "ias_student_info = pd.read_csv(data_root + 'IAS_STUDENT_INFO_V_UGRD.csv')\n",
    "ias_student_info.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca219585",
   "metadata": {},
   "source": [
    "## INCOME_FLAGS_UGRD_20142015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354ef999",
   "metadata": {},
   "outputs": [],
   "source": [
    "ias_income_flags = pd.read_csv(data_root + 'INCOME_FLAGS_UGRD_20142015.csv')\n",
    "ias_income_flags.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bcc94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ias_income_flags['LOW_INCOME_FLAG'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d4ab4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset has only one value 'Daily'\n",
    "# DEPENDENCY_STATUS and NUM_IN_HOUSEHOLD are majorly missing , 59%\n",
    "ias_income_flags.drop(columns=['DATASET', 'DEPENDENCY_STATUS', 'NUM_IN_HOUSEHOLD', 'POVERTY_INDEX_YEAR'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccce1dee",
   "metadata": {},
   "source": [
    "## PS_STDNT_AID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd82e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_student_aid = pd.read_csv(data_root + 'PS_STDNT_AID.csv')\n",
    "\n",
    "# INSTITUTION is always UVA01\n",
    "ps_student_aid.drop(columns=['INSTITUTION'], inplace=True) \n",
    "ps_student_aid.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28fb01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_student_aid[ps_student_aid.isna().any(axis=1)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62f9b687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# droping NaNs\n",
    "ps_student_aid.dropna(inplace=True)\n",
    "\n",
    "# the data after 2023 is future data, hence changeable\n",
    "# disbursement file start from 2014\n",
    "# ps_student_aid = ps_student_aid[\n",
    "#     (ps_student_aid['AID_YEAR']>=2014) &\n",
    "#     (ps_student_aid['AID_YEAR']<=2023)\n",
    "# ]\n",
    "# surprisingly this id is float in this file. Which shouldn't be the case\n",
    "ps_student_aid['PARTY_DIM_ID'] = ps_student_aid['PARTY_DIM_ID'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fdafa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_student_aid.groupby('AID_YEAR')['INST_NEED'].sum().reset_index().tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f7a496",
   "metadata": {},
   "source": [
    "## TERM_DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66c2e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "term_dim = pd.read_csv(data_root + 'TERM_DIM.csv')\n",
    "column_mask = [col for col in term_dim.columns if 'ETL' not in col]\n",
    "term_dim= term_dim[column_mask]\n",
    "term_dim.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4c1f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a lot of missing values\n",
    "term_dim[term_dim.isna().any(axis=1)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5017a060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'Shape before {term_dim.shape}')\n",
    "# # only the first two rows are NaN\n",
    "# term_dim.dropna(inplace=True)\n",
    "# print(f'Shape after dropping NaNs {term_dim.shape}')\n",
    "\n",
    "# print('We are only considering Fall terms for now')\n",
    "# term_dim = term_dim[term_dim['TERM_TYPE']=='Fall']\n",
    "\n",
    "print('Keeping only undergrad students')\n",
    "term_dim = term_dim[term_dim['ACADEMIC_CAREER']=='UGRD']\n",
    "# we can safely drop term type now\n",
    "\n",
    "term_dim['CALENDAR_YEAR'] = term_dim['CALENDAR_YEAR'].astype(int)\n",
    "# print('Dropping terms after calendar year 2023.')\n",
    "# term_dim = term_dim[term_dim['CALENDAR_YEAR']<2024]\n",
    "\n",
    "drop_columns = ['TERM_DESC', 'ACADEMIC_CAREER', 'ACADEMIC_YEAR']\n",
    "print(f'Dropping columns {drop_columns}')\n",
    "term_dim.drop(columns=drop_columns, inplace=True)\n",
    "\n",
    "term_dim.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b0afc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TERM_DIM_ID is the primary key here and unique to a term regardless of the year\n",
    "print(term_dim['TERM_DIM_ID'].nunique() == term_dim.shape[0])\n",
    "\n",
    "# disbursement file only has complete year info from calendar year 2015 to 2023\n",
    "# term_dim[term_dim['TERM_DIM_ID'].isin(disbursement['TERM_DIM_ID'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c04fe1d",
   "metadata": {},
   "source": [
    "## STUDENT_TERM_FACT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5668f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_term_fact = pd.read_csv(data_root + 'STUDENT_TERM_UGRD_20142015.csv')\n",
    "\n",
    "column_mask = [col for col in student_term_fact.columns if 'ETL' not in col]\n",
    "student_term_fact = student_term_fact[column_mask]\n",
    "student_term_fact.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57502636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# almost always `Y`, so can be safely dropped\n",
    "student_term_fact['FIN_AID_PROG_ELIGIBILITY_FLAG'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eee569",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_term_fact = student_term_fact[\n",
    "    student_term_fact['BILLING_CAREER']=='UGRD'\n",
    "]\n",
    "\n",
    "min_aid_year = disbursement['AID_YEAR'].min()\n",
    "print(min_aid_year)\n",
    "\n",
    "student_term_fact = student_term_fact[\n",
    "    student_term_fact['FINANCIAL_AID_ACADEMIC_YEAR'] >= min_aid_year\n",
    "]\n",
    "\n",
    "student_term_fact['ACADEMIC_LEVEL_TERM_START'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6936045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these outliers are rare\n",
    "print(f'Dropping non set and post-bacc undergrads')\n",
    "student_term_fact = student_term_fact[\n",
    "    ~student_term_fact['ACADEMIC_LEVEL_TERM_START'].isin(\n",
    "        ['Not Set', 'Post-Bacc Undergraduate']\n",
    "    )\n",
    "]\n",
    "\n",
    "student_term_fact.rename({\n",
    "    'PRIM_ACADEMIC_PROGRAM_DIM_ID': 'PROGRAM_DIM_ID',\n",
    "    'FINANCIAL_AID_ACADEMIC_YEAR': 'AID_YEAR'\n",
    "}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac857d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# few nan values which can be safely dropped\n",
    "student_term_fact['FIN_AID_FED_RES'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493faed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# few outliers with None and Y values. can safely drop them\n",
    "student_term_fact = student_term_fact[student_term_fact['FIN_AID_FED_RES'].isin(['V', 'N'])]\n",
    "\n",
    "student_term_fact[student_term_fact['PARTY_DIM_ID']==2048271]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "317a023d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# student_term_fact.groupby(['AID_YEAR', 'TERM_DIM_ID', 'PARTY_DIM_ID']).size().reset_index()\n",
    "# there were two entries for a party in each aid year and term id, so we need to drop them\n",
    "student_term_fact.drop_duplicates(\n",
    "    subset='STUDENT_TERM_FACT_ID',\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7886be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostly approved full-time\n",
    "student_term_fact['APPROVED_ACADEMIC_LOAD'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "581c00bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_term_fact.drop(\n",
    "    columns=[\n",
    "        'STUDENT_TERM_FACT_ID', 'BILLING_CAREER', 'FIRST_TERM_IN_CAREER_DIM_ID',\n",
    "        'FINANCIAL_AID_LOAD', 'APPROVED_ACADEMIC_LOAD', # these two loads are almost same \n",
    "        'FIN_AID_PROG_ELIGIBILITY_FLAG'],\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953e5472",
   "metadata": {},
   "source": [
    "# Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7df35f",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "afeb6507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(left:pd.DataFrame, right:pd.DataFrame, key:list|str=None, how='inner'):\n",
    "    common = set(left.columns) & set(right.columns)\n",
    "    \n",
    "    # if no key is provided, assume the common columns that \n",
    "    # ends with '_ID' or  '_YEAR' are the common keys\n",
    "    if key is None:\n",
    "        key = [\n",
    "            column for column in common \n",
    "                if left[column].dtype in [object, str] or column.endswith('_YEAR') or column.endswith('_ID')\n",
    "        ]\n",
    "        if len(key)>0:\n",
    "            print(f'Found key {key}.')\n",
    "        else:\n",
    "            print('Error ! no common key IDs found. Returning None.')\n",
    "            return None\n",
    "    \n",
    "    if type(key) != list: \n",
    "        common = [col for col in common if col != key]\n",
    "    else:\n",
    "        common = [col for col in common if col not in key]\n",
    "        \n",
    "    merged_data = left.merge(right.drop(columns=common), on = key, how=how)\n",
    "    print(f'Shape: left {left.shape}, right {right.shape}, merged {merged_data.shape}.\\n')\n",
    "    \n",
    "    return merged_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2df739",
   "metadata": {},
   "source": [
    "## Disbursement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c888a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aid file doesn't have info for all students in the disbursement file, hence left join\n",
    "df = merge(disbursement, ps_student_aid, how='left')\n",
    "\n",
    "# some terms of 2024 will be dropped\n",
    "df = merge(df, term_dim)\n",
    "\n",
    "# income flag doesn't have info for all students in the disbursement file, hence left join\n",
    "df = merge(df, ias_income_flags, how='left')\n",
    "\n",
    "# not set and post-bacc students will be dropped, hence file size will decrease\n",
    "df = merge(df, student_term_fact)\n",
    "\n",
    "academic_program_dim.rename(\n",
    "    {'ACADEMIC_PROGRAM_DIM_ID': 'PROGRAM_DIM_ID'}, \n",
    "    axis=1, inplace=True\n",
    ")\n",
    "# added ACADEMIC_PROGRAM_DESC\n",
    "df = merge(df, academic_program_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed662531",
   "metadata": {},
   "source": [
    "## Fill missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1a31e4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_percentage(df, nonzero_only=True):\n",
    "    results = df.isnull().mean().round(4).mul(100).sort_values(ascending=False)\n",
    "    if nonzero_only:\n",
    "        results = results[results>0]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd056c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for any missing values\n",
    "missing_df = missing_percentage(df)\n",
    "missing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62e7b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Imputing missing values\\n')\n",
    "\n",
    "for col in missing_df.index:\n",
    "    column_type = df[col].dtype\n",
    "    isnumeric = df[col].dtype in [int, float]\n",
    "    \n",
    "    print(f'Column {col}, type {df[col].dtype}, is numeric {isnumeric}')\n",
    "    \n",
    "    if isnumeric:\n",
    "        print('Filling with zero')\n",
    "        df[col] = df[col].fillna(0)\n",
    "    else:\n",
    "        most_freq = df[col].value_counts().reset_index().iloc[0,0]\n",
    "        print(f'Filling with the most freq item: {most_freq}')\n",
    "        df[col] =df[col].fillna(most_freq)\n",
    "    print()\n",
    "    \n",
    "print(df.shape)\n",
    "df.dropna(inplace=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b6d120",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1617e96",
   "metadata": {},
   "source": [
    "## Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69619d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funds are mostly disbursed in Fall and Spring sessions\n",
    "df['TERM_TYPE'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b253be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funding freq is balanced despite level difference\n",
    "df['ACADEMIC_LEVEL_TERM_START'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50602675",
   "metadata": {},
   "source": [
    "# Aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea664a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_column = 'AID_YEAR' # 'CALENDAR_YEAR'\n",
    "print(sorted(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720f1710",
   "metadata": {},
   "source": [
    "## Group ids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ab3371cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_key = [\n",
    "    'ACADEMIC_LEVEL_TERM_START',\n",
    "    'ACADEMIC_PLAN',\n",
    "    'ACADEMIC_PROGRAM_DESC',\n",
    "    'FIN_AID_FED_RES',\n",
    "    'UVA_ACCESS', \n",
    "    'REPORT_CODE',\n",
    "    'Need based',\n",
    "    # 'PROGRAM_DIM_ID', # using ACADEMIC_PROGRAM_DESC instead since that has less unique counts\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bf07baee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsets(columns):\n",
    "    result = [[]]\n",
    "    for column in columns:\n",
    "        result += [subset + [column] for subset in result]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb8e765",
   "metadata": {},
   "source": [
    "## Total party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f1a8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "academic_groupby_key = [\n",
    "    'ACADEMIC_LEVEL_TERM_START','ACADEMIC_PLAN',\n",
    "    'ACADEMIC_PROGRAM_DESC'\n",
    "]\n",
    "enrolled_students = merge(\n",
    "    student_term_fact, academic_program_dim\n",
    ")\n",
    "enrolled_students = merge(enrolled_students, term_dim)\n",
    "# temp = temp[temp['TERM_TYPE'].isin(['Spring', 'Fall'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f885c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Shape before {enrolled_students.shape}')\n",
    "enrolled_students.drop_duplicates(['PROGRAM_DIM_ID', 'PARTY_DIM_ID', 'TERM_DIM_ID'], inplace=True)\n",
    "print(f'Shape after dropping duplicates {enrolled_students.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a346d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update this list based on the previous groupby_key\n",
    "total_party_by_group = enrolled_students.groupby(\n",
    "    academic_groupby_key + [time_column]\n",
    ")['PARTY_DIM_ID'].nunique().reset_index(name='TOTAL_PARTY')\n",
    "total_party_by_group.groupby(time_column)['TOTAL_PARTY'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7e05d17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_party_by_group = total_party_by_group[academic_groupby_key + [time_column] + ['TOTAL_PARTY']]\n",
    "\n",
    "groups = []\n",
    "for subset in subsets(academic_groupby_key):\n",
    "    if len(subset) == len(academic_groupby_key): continue\n",
    "    \n",
    "    grouped = enrolled_students.groupby(\n",
    "        subset + [time_column]\n",
    "    )['PARTY_DIM_ID'].nunique().reset_index(name='TOTAL_PARTY')\n",
    "    \n",
    "    if len(subset)>0:\n",
    "        temp = grouped.merge(total_party_by_group[academic_groupby_key], on=subset)\n",
    "    \n",
    "    for column in academic_groupby_key:\n",
    "        if column in subset: continue\n",
    "        # if len(subset) >0:\n",
    "        #     if temp[column].nunique()==1: continue\n",
    "            \n",
    "        grouped[column] = 'Total'\n",
    "    \n",
    "    grouped = grouped[academic_groupby_key + [time_column] + ['TOTAL_PARTY']]\n",
    "    groups.append(grouped)\n",
    "\n",
    "groups = pd.concat(groups, axis=0)\n",
    "total_party_by_group = pd.concat([total_party_by_group, groups], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2d669668",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_extra_total_rows(df, groupby_key):\n",
    "    # the issue with the adding Total category is that when only one unique value \n",
    "    # is present in target column, adding Total aggregation is unnecessary. \n",
    "    # Which will have same target values since it is aggregated for one value. \n",
    "    # This is not what we want. The following code removes these rows\n",
    "    print(f'Original size {df.shape}')\n",
    "    \n",
    "    for target_column in groupby_key:\n",
    "        print(f'Processing {target_column}')\n",
    "        groupby_without_target = [\n",
    "            column for column in groupby_key if column != target_column\n",
    "        ]\n",
    "        \n",
    "        others = []\n",
    "        for subgroup_key, subgroup in tqdm(df.groupby(groupby_without_target)):\n",
    "            values = subgroup[target_column].unique()\n",
    "            if len(values) != 2 or 'Total' not in values:\n",
    "                others.append(subgroup[groupby_key].drop_duplicates())\n",
    "            else:\n",
    "                temp = subgroup[groupby_key][subgroup[target_column] != 'Total']\n",
    "                others.append(temp.drop_duplicates())\n",
    "        \n",
    "        others = pd.concat(others, axis=0).reset_index(drop=True)\n",
    "        \n",
    "        df = df.merge(others[groupby_key], on=groupby_key)\n",
    "        print(f'Reduced {df.shape}')\n",
    "        gc.collect()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cf2cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_party_by_group = drop_extra_total_rows(\n",
    "#     total_party_by_group, academic_groupby_key\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e59c7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(total_party_by_group.shape)\n",
    "total_party_by_group = total_party_by_group.drop_duplicates(subset=academic_groupby_key + [time_column])\n",
    "print(f'Shape after dropping duplicates {total_party_by_group.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "792fc914",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_party_by_group.to_csv(data_root + 'total_party_by_group.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b89e99",
   "metadata": {},
   "source": [
    "## Funded party"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23afefe2",
   "metadata": {},
   "source": [
    "### Unique parties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4dd58527",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby(groupby_key + [time_column])[[\n",
    "    'INST_NEED', 'OFFER_BALANCE'\n",
    "]]\n",
    "\n",
    "funded_party = df.groupby(groupby_key + [time_column])[[\n",
    "    'INST_NEED', 'OFFER_BALANCE'\n",
    "]].sum().reset_index()\n",
    "\n",
    "# how many unique parties got funded over a year\n",
    "funded_party['FUNDED_PARTY'] = df.groupby(\n",
    "    groupby_key + [time_column]\n",
    ")['PARTY_DIM_ID'].nunique().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5e3ece51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby key, time column, all other columns\n",
    "columns = groupby_key + [time_column] + ['INST_NEED', 'OFFER_BALANCE', 'FUNDED_PARTY']\n",
    "assert list(funded_party.columns) == columns,\\\n",
    "    f\"Dataframe columns {funded_party.columns} do not match with rearranged {columns} columns\"\n",
    "\n",
    "funded_party = funded_party[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8ca53e",
   "metadata": {},
   "source": [
    "### Add `Total` category\n",
    "This is for dashboard view, when no single category is selected. For example, when no academic level is selected, default should show values aggregated for all levels. Hence we add a new label `Total` for such object features. This is also helpful for hierarchical forecasting, where we need aggreaged values at different hierarchies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e178215a",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = []\n",
    "for subset in subsets(groupby_key):\n",
    "    if subset == groupby_key: continue\n",
    "    \n",
    "    grouped = df.groupby(subset + [time_column]\n",
    "    )['PARTY_DIM_ID'].nunique().reset_index(name='FUNDED_PARTY')\n",
    "    \n",
    "    grouped[['INST_NEED', 'OFFER_BALANCE']] = df.groupby(\n",
    "        subset + [time_column]\n",
    "    )[['INST_NEED', 'OFFER_BALANCE']].sum().values\n",
    "    \n",
    "    if len(subset) > 0:\n",
    "        temp = grouped.merge(funded_party[groupby_key], on=subset)\n",
    "        \n",
    "    for column in groupby_key:\n",
    "        if column in subset: continue\n",
    "        # if len(subset) >0:\n",
    "        #     if temp[column].nunique()==1: continue\n",
    "            \n",
    "        grouped[column] = 'Total'\n",
    "    \n",
    "    # align columns for row-wise concat\n",
    "    grouped = grouped[columns]\n",
    "    groups.append(grouped)\n",
    "\n",
    "groups = pd.concat(groups, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661d9166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# groups = drop_extra_total_rows(groups, groupby_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "12b7c92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups.to_csv('datawarehouse/groups.csv', index=False)\n",
    "# groups = pd.read_csv('datawarehouse/groups.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352def08",
   "metadata": {},
   "outputs": [],
   "source": [
    "funded_party = pd.concat([funded_party, groups], axis=0).reset_index(drop=True)\n",
    "print(funded_party.shape)\n",
    "\n",
    "funded_party = funded_party.drop_duplicates(groupby_key + [time_column])\n",
    "print(f'Shape after dropping duplicates {funded_party.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb075a1",
   "metadata": {},
   "source": [
    "## Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c264c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add group id\n",
    "ground_id = funded_party.groupby(groupby_key)[\n",
    "    ['OFFER_BALANCE']\n",
    "].sum().reset_index().reset_index(names='GROUP_ID')\n",
    "\n",
    "ground_id.drop(columns='OFFER_BALANCE', inplace=True)\n",
    "print(f'Group size {ground_id.shape}')\n",
    "\n",
    "print(ground_id.head(3))\n",
    "\n",
    "# add funded student info\n",
    "funded_party = merge(ground_id, funded_party, key=groupby_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f73ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add student term file info, which includes all students, funded or not\n",
    "# not that this info is only unique per the academic_groupby_key\n",
    "# so summing by the groupby_key will count duplicates\n",
    "summed = merge(funded_party, total_party_by_group)\n",
    "summed = summed.drop_duplicates(subset=groupby_key + [time_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de361f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summed = drop_extra_total_rows(summed, groupby_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200b2a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summed.groupby('GROUP_ID')[['COUNT', 'INST_NEED',\t'OFFER_BALANCE']].sum().reset_index()\n",
    "yearly = summed[(summed!='Total').all(axis=1)\n",
    "    ].groupby(time_column)[['INST_NEED','OFFER_BALANCE']].sum().reset_index()\n",
    "yearly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca13dae",
   "metadata": {},
   "source": [
    "# Fill missing steps\n",
    "\n",
    "For the time series analysis to work smoothly the different time series groups here needs to be of same length. Which it currently isn't because some funding may be available from 2014, when some might be introduced later. This section imputes those previous missing steps with 0, thus making all of this group lengths same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9fff63fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "summed.to_csv(data_root + 'summed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c342b1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Shape before filling the missing timesteps {summed.shape}')\n",
    "\n",
    "min_year, max_year = df[time_column].min(), df[time_column].max()\n",
    "print(f'Min year {min_year}, max year {max_year}.')\n",
    "years = pd.DataFrame(\n",
    "    {time_column: range(min_year, max_year+1)}\n",
    ")\n",
    "merged = []\n",
    "\n",
    "for group_key, group in tqdm(summed.groupby(groupby_key)):\n",
    "    if group.shape[0] == 1:\n",
    "        continue\n",
    "    \n",
    "    filled = years.merge(group, on=time_column, how='left')\n",
    "    filled[groupby_key] = group_key\n",
    "    filled['GROUP_ID'] = group['GROUP_ID'].values[0]\n",
    "    merged.append(filled.fillna(0))\n",
    "\n",
    "merged = pd.concat(merged, axis=0).reset_index(drop=True)\n",
    "print(f'Shape after filling the missing timesteps {merged.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e79486",
   "metadata": {},
   "source": [
    "# Dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1d1a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1a461991",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv(\n",
    "    data_root + 'Merged2.csv', index=False\n",
    ")\n",
    "\n",
    "df.to_csv(\n",
    "    data_root + 'Total2.csv', index=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
